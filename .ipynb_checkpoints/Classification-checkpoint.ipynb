{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jianjin/anaconda/envs/mlbook/lib/python3.5/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/jianjin/anaconda/envs/mlbook/lib/python3.5/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.datasets import fetch_mldata\n",
    "#mnist = fetch_mldata('MNIST original')\n",
    "#mnist\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist['data'],mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112467438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "some_indice = np.random.randint(len(X))\n",
    "some_digit = X[some_indice]\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(y[some_indice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is actually already split into a training set (the first 60,000 images) and a test set (the last 10,000 images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s also shuffle the training set; this will guarantee that all cross-validation folds will be similar (you don’t want one fold to be missing some digits). Moreover, some learning algorithms are sensitive to the order of the training instances, and they perform poorly if they get many similar instances in a row. Shuffling the dataset ensures that this won’t happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s simplify the problem for now and only try to identify one digit—for example, the number 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train==5)\n",
    "y_test_5 = (y_test==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42,max_iter = 5)\n",
    "sgd_clf.fit(X_train,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance with Cross-Validation (Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating a classifier is often significantly trickier than evaluating a regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9675355 , 0.96346667, 0.96113333, 0.96133076])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf,X_train,y_train_5,\n",
    "                scoring='accuracy',cv =4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "over 95% accuracy! really? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5923., 6742., 5958., 6131., 5842., 5421., 5918., 6265., 5851.,\n",
       "        5949.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11429c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train,rwidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see, the proportion of each number is close to 10%. So even if we guess all the numbers is not 5, we can get a 90% accuracy rate.\n",
    "\n",
    "This demonstrates why accuracy is generally not the preferred performance measure for classifiers, especially when you are dealing with skewed datasets (i.e., when some classes are much more frequent than others)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf,X_train,y_train_5,cv=3)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53468,  1111],\n",
       "       [ 1281,  4140]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Rate: the probability you detect something\n",
    "Precision Rate: the probability you are correct when you detect something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636967349197565"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884212530946486"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often convenient to combine precision and recall into a single metric called the F1 score, in particular if you need a simple way to compare two classifiers. The F1 score is the harmonic mean of precision and recall. Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. As a result, the classifier will only get a high F1 score if both recall and precision are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7758620689655172"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 score favors classifiers that have similar precision and recall. This is not always what you want**: in some contexts you mostly care about precision, and in other contexts you really care about recall.\n",
    "\n",
    "For example, if you trained a classifier to detect videos that are safe for kids, you would probably prefer a classifier that rejects many good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few really bad videos show up in your product (in such cases, you may even want to add a human pipeline to check the classifier’s video selection). On the other hand, suppose you train a classifier to detect shoplifters on surveillance images: it is probably fine if your classifier has only 30% precision as long as it has 99% recall (sure, the security guards will get a few false alerts, but almost all shoplifters will get caught).\n",
    "\n",
    "Unfortunately, you can’t have it both ways: increasing precision reduces recall, and vice versa. This is called the precision/recall tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some algorithms (such as Random Forest classifiers or naive Bayes classifiers) are capable of handling multiple classes directly. Others (such as Support Vector Machine classifiers or Linear classifiers) are strictly binary classifiers. However, there are various strategies that you can use to perform multiclass classification using multiple binary classifiers.\n",
    "\n",
    "For example, one way to create a system that can classify the digit images into 10 classes (from 0 to 9) is to train 10 binary classifiers, one for each digit (a 0-detector, a 1-detector, a 2-detector, and so on). Then when you want to classify an image, you get the decision score from each classifier for that image and you select the class whose classifier outputs the highest score. This is called the one-versus-all (OvA) strategy (also called one-versus-the-rest).\n",
    "\n",
    "Another strategy is to train a binary classifier for every pair of digits: one to distinguish 0s and 1s, another to distinguish 0s and 2s, another for 1s and 2s, and so on. This is called the one-versus-one (OvO) strategy. If there are N classes, you need to train N × (N – 1) / 2 classifiers. For the MNIST problem, this means training 45 binary classifiers! When you want to classify an image, you have to run the image through all 45 classifiers and see which class wins the most duels. The main advantage of OvO is that each classifier only needs to be trained on the part of the training set for the two classes that it must distinguish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> sgd_clf.fit(X_train, y_train)  # y_train, not y_train_5\n",
    ">>> sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86622241, 0.86568905, 0.88633333, 0.8312078 , 0.8822941 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf,X_train,y_train,scoring='accuracy',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90926815, 0.91229561, 0.90948642])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.preprocessing import StandardScaler\n",
    ">>> scaler = StandardScaler()\n",
    ">>> X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    ">>> cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
